---
title: "Project-3-stacked"
author: "George Paul,"
date: "2023-03-29"
output: 
  prettydoc::html_pretty:
    theme: cayman
---

# Problem Statement
We are assuming the role of a consulting firm, hired by the company IBM to analyze their attrition data. IBM executives would like to be able to predict which employees will choose to leave the company, ideally for two reasons: retaining high-performing employees, and letting low-performing employees quit rather than offering a severance package. Our task is to build this model, and IBM has provided us with data on employees, both employees that have left the company and employees that have not left. We are given information on employees' personal lives, such as age, gender, relationship status, as well as information about their job satisfaction. As for job satisfaction, we have information on pay, raises, as well as survey responses about feelings about job involvement and job/environment satisfaction. We will proceed by fitting several models and predicting onto a test set, and using these outputs as predictors for our final stacked models. Our success will be measured by analyzing the kappa value, to see if we truly can predict which employees will stay or leave.

# Libraries
```{r}
library(class)
library(janitor)
library(neuralnet)
library(caret)
library(kernlab)
library(C50)
library(randomForest)
```

# Combined Data Frame
Below we read in several csv files, which are the outputs of our first-levels fitted models. We will combine these predictions together to make our final data frame, and these predictions will now be used as input variables to make our final models.
```{r}
test.labels <- read.csv("test.labels.csv")
ann.preds <- read.csv("ann.preds.csv")
tree.preds <- read.csv("decision.tree.csv")
knn.preds <- read.csv("employees.knn.csv")
logreg.preds <- read.csv("logreg.preds.csv")
rm.preds <- read.csv("rm.preds.csv")
svm.preds <- read.csv("svm.preds.csv")

combined.df <- data.frame(Attrition = test.labels[,2],
                          ann = ann.preds[,2],
                          tree = tree.preds[,2],
                          knn = knn.preds[,2],
                          logreg = logreg.preds[,2],
                          rm = rm.preds[,2],
                          svm = svm.preds[,2])

combined.df$Attrition <- as.factor(combined.df$Attrition)
combined.df$tree <- as.factor(combined.df$tree)
combined.df$rm <- as.factor(combined.df$rm)
combined.df$svm <- as.factor(combined.df$svm)

combined.df <- clean_names(combined.df)
kappa.table <- read.csv("kappa.table.csv")
kappa.table$X <- NULL
```

# New Train/Test
```{r}
n2 <- nrow(combined.df)
set.seed(0)
idx2 <- sample(n2, n2*.7)

final.train <- combined.df[idx2,]
final.test <- combined.df[-idx2,]
```

# Fit Final Models

## Random Forest
```{r}
set.seed(1)
final.rf <- randomForest(attrition ~ ., data = final.train)
final.rf.preds <- predict(final.rf, final.test)
confusionMatrix(final.rf.preds, final.test$attrition)
final.rf.kappa <- confusionMatrix(final.rf.preds, final.test$attrition)$overall[2]
```

## Boosted Decision Tree
```{r}
ctrl <- trainControl(method = "cv", number = 10,
                     selectionFunction = "oneSE")

grid_tree <- expand.grid(.trials = c(1,5,10),
                         .model = "tree",
                         .winnow = "FALSE")
final.tree <- train(attrition ~ ., data = final.train, method = "C5.0",
           metric = "Kappa",
           trControl = ctrl,
           tuneGrid = grid_tree)
final.tree
final.tree.preds <- predict(final.tree, final.test)
confusionMatrix(final.tree.preds, final.test$attrition)
final.tree.kappa <- confusionMatrix(final.tree.preds, final.test$attrition)$overall[2]
```

# Graphs/Figures
```{r}
kappa.table[7,1] <- "Final RF"
kappa.table[7,2] <- final.rf.kappa
kappa.table[8,1] <- "Final Tree"
kappa.table[8,2] <- final.tree.kappa

barplot(kappa.table$kappa, names.arg = kappa.table$model, xlab = "model", ylab = "kappa")
```

# Summary of Results
The kappa values of our final models are not extremely high, both floating in the 0.3 to 0.4 range, which is notably similar to the kappa values of the first level model. This implies that our models are not extremely effective in predicting which employees will leave. 
However, given that the first level models generally had low kappa values, it is possible that this dataset is not particularly telling of trends in IBM's employee attrition. Perhaps the dataset is missing an underlying reason of why employees leave, or it could also be true that we cannot find the true relationships without more data. The dataset only contained the records of 1,470 employees, which is a relatively small amount of data to attempt to model with. Perhaps with more data, a more effective model could be built to satsify IBM's business need.

## Identification of Significant Predictors (TODO)

## Clustering Results
We ran the clustering algorithms in the dataset, and we found the optimal number of clusters was 3. We then created a final cluster assignment using k-means clustering with k = 3. Below shows the average attrition rate by cluster:
```{r, echo=F}
cluster_attrition <- read.csv("cluster_attrition.csv")
cluster_attrition$X <- NULL
cluster_attrition
```
There appears to be one cluster with significantly higher attrition rates. Based on looking at the centers of the 3 clusters, we found the following attributes to be true of the cluster with the highest attrition rate:
* Younger
* Fewer Years in Current Role
* Unmarried
* More sales representatives
* Fewer total working years
* Fewer Years at Company

While the results of clustering seemed promise at first, we are hesitant to use clusters as a prediction rule for the following two reasons:
* These variables are mostly correlated. Younger employees would naturally have had fewer total working years, fewer years at company, be unmarried, etc.
* These variables are largely similar to the variables our models used to make predictions. Using these clusters wouldn't add anything to the models we already built.